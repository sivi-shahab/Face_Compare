# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: core
  name: {{ .Values.core.name }}
spec:
  replicas: {{ .Values.core.replicas }} # You can adjust the number of replicas as needed
  selector:
    matchLabels:
      app: core
  template:
    metadata:
      labels:
        app: core
    spec:
      containers:
        - env:
            - name: ML_PORT
              value: "{{ .Values.core.port }}"
            - name: IMG_LENGTH_LIMIT
              value: "{{ .Values.max_detect_size }}"
            - name: UWSGI_PROCESSES
              value: "{{ .Values.uwsgi_processes | default "2" }}"
            - name: UWSGI_THREADS
              value: "{{ .Values.uwsgi_threads | default "1" }}"
          image: {{ .Values.core.repository }}:{{ .Values.core.tag }}
          ports:
          - containerPort: {{ .Values.core.port }}
          name: {{ .Values.core.name }}
          resources:
            limits:
              nvidia.com/gpu: {{ .Values.gpuCount }}
            requests:
              nvidia.com/gpu: {{ .Values.gpuCount }}
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-t4
      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: compreface-core
spec:
  type: ClusterIP
  selector:
    app: core
  ports:
    - port: {{ .Values.core.port }}
